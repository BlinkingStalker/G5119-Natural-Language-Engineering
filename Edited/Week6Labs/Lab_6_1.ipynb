{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 (Part 1): Supervised WSD\n",
    "\n",
    "In the first part of this week we will be looking at corpus-based methods for carrying out word sense disambiguation.  In particular, we will:\n",
    "* introduce SemCor, a sense-tagged subsection of the Brown Corpus.\n",
    "* build Naive Bayes classifiers to carry out sense disambiguation for words with two senses\n",
    "\n",
    "First some preliminary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import operator\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#On first run, you will probably need to uncomment the following line and run this cell\n",
    "#nltk.download('semcor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SemCor\n",
    "SemCor is a collection of 352 documents which have been annotated in various ways (annotations include POS tags and WordNet synsets for individual words\n",
    "\n",
    "`semcor.fileids()` returns a list of all of the individual document ids in SemCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "352"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "allfiles=semcor.fileids() #list of fileids\n",
    "len(allfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`semcor.raw(fileid)` returns the raw text of the given file.  Note that this is marked-up using XML and is probably best avoided unless there is no other way to access the information you require from the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nsemcor.raw(allfiles)\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "\"\"\"\n",
    "semcor.raw(allfiles)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other potentially useful SemCor functions include:\n",
    "\n",
    "* `semcor.words(fileid)`: returns a list of tokens for each file\n",
    "* `semcor.chunks(fileid)`: returns a list of *chunks* for each file, where a chunk identifies multiword (generally non-compositional) phrases\n",
    "* `semcor.tagged_chunks(fileid,tagtype)`: returns the tagged chunks of the file where the tagtype can be *pos* or *sem*.  We are interested in the *sem* tags which are the WOrdNet synsets\n",
    "* `semcor.tagged_sentences(fileid,tagtype)`: maintains the sentence boundaries within the file and therefore returns a list of lists (one for each sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "semcor.words(allfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['The'], ['Fulton', 'County', 'Grand', 'Jury'], ...]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "semcor.chunks(allfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['The'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]), ...]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "semcor.tagged_chunks(allfiles[0],tag='sem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['The'],\n Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]),\n Tree(Lemma('state.v.01.say'), ['said']),\n Tree(Lemma('friday.n.01.Friday'), ['Friday']),\n ['an'],\n Tree(Lemma('probe.n.01.investigation'), ['investigation']),\n ['of'],\n Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']),\n [\"'s\"],\n Tree(Lemma('late.s.03.recent'), ['recent']),\n Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']),\n Tree(Lemma('produce.v.04.produce'), ['produced']),\n ['``'],\n ['no'],\n Tree(Lemma('evidence.n.01.evidence'), ['evidence']),\n [\"''\"],\n ['that'],\n ['any'],\n Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']),\n Tree(Lemma('happen.v.01.take_place'), ['took', 'place']),\n ['.']]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "tagged_sentences=semcor.tagged_sents(allfiles[0],tag='sem')\n",
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this exercise, we are interested in single words which have been tagged with a WordNet Lemma or synset.  We now define a couple of functions to help us extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def extract_tags(taggedsentence):\n",
    "    '''\n",
    "    For a tagged sentence in SemCor, identify single words which have been tagged with a WN synset\n",
    "    taggedsentence: a list of items, some of which are of type wordnet.tree.Tree\n",
    "    :return: a list of pairs, (word,synset)\n",
    "    \n",
    "    '''\n",
    "    alist=[]\n",
    "    for item in taggedsentence:\n",
    "        if isinstance(item,nltk.tree.Tree):   #check with this is a Tree\n",
    "            if isinstance(item.label(),nltk.corpus.reader.wordnet.Lemma) and len(item.leaves())==1:\n",
    "                #check whether the tree's label is Lemma and whether the tree has a single leaf\n",
    "                #if so add the pair (lowercased leaf,synsetlabel) to output list\n",
    "                alist.append((item.leaves()[0].lower(),item.label().synset()))\n",
    "    return alist\n",
    "            \n",
    "\n",
    "def extract_senses(fileid_list):\n",
    "    '''\n",
    "    apply extract_tags to all sentences in all documents in a list of file ids\n",
    "    fileid_list: list of ids\n",
    "    :return: list of list of (token,tag) pairs, one for each sentence in corpus\n",
    "    '''\n",
    "    sentences=[]\n",
    "    for fileid in fileid_list:\n",
    "        print(\"Processing {}\".format(fileid))\n",
    "        sentences+=[extract_tags(taggedsentence) for taggedsentence in semcor.tagged_sents(fileid,tag='sem')]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test this on the first document in the fileid list.  Notice that it takes a while to process a single file in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#some_sentences=extract_senses([allfiles[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "Write a function `find_sense_distributions()` which finds the distribution of senses for every word in a list of sentences (in the format returned by `extract_sentences()`).  Your output should be a dictionary of dictionaries.  The key to the outermost dictionary should be the word_form and the key to the inner dictionaries should be the sense tag.\n",
    "\n",
    "Test your function on `some_sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def find_sense_distributions(some_sentences):\n",
    "    allwords={}\n",
    "    for sentence in some_sentences:\n",
    "        for(word, sense) in sentence:\n",
    "            thisword=allwords.get(word,{})\n",
    "            thisword[sense]=thisword.get(sense,0)+1\n",
    "            allwords[word]=thisword\n",
    "    return allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#find_sense_distributions(some_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "Write a function which returns a list of words which only occur with one sense in the corpus, ordered by frequency (most frequent first).\n",
    "\n",
    "Test your function on `some_sentences`.  You should find that the fourth most frequently occurring seemingly monosemous word is *georgia* which occurs 6 times in this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def find_monosemous(sense_dists):\n",
    "    mono=[]\n",
    "    for key,worddict in sense_dists.items():\n",
    "        if len(worddict.keys())==1:\n",
    "            mono.append((key,sum(worddict.values())))\n",
    "    return sorted(mono, key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#find_monosemous(find_sense_distributions(some_sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "Write a function `find_candidates()` which will find words which \n",
    "* have 2 senses in the sample, \n",
    "* occurrences of which are roughly balanced between the two classes (between 30% and 70%)\n",
    "* are as frequent as possible\n",
    "\n",
    "Test it on `some_sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def find_candidates(sense_dists):\n",
    "    cands=[]\n",
    "    for key, worddict in sense_dists.items():\n",
    "        if len(worddict.keys())==2:\n",
    "            freq=sum(worddict.values())\n",
    "            p=list(worddict.values())[0]/freq\n",
    "            if p>0.3 and p <0.7:\n",
    "                cands.append((key,freq,p))    \n",
    "    return sorted(cands,key=operator.itemgetter(1),reverse=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#find_candidates(find_sense_distributions(some_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to apply our functions to larger samples.  Here we will define two sets of sentences `training_sentences` and `testing_sentences`.  We are going to choose a random sample of the documents for testing.  We can achieve this by randomly shuffling the fileids and then assigning documents in the first part of the list to training and documents in the second part of the list to testing.  By setting the random seed, we ensure reproducibility of our results (since the random shuffle will be the same each time we run the cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['brownv/tagfiles/br-a29.xml', 'brownv/tagfiles/br-l06.xml', 'brown2/tagfiles/br-e31.xml', 'brownv/tagfiles/br-c06.xml', 'brown2/tagfiles/br-j34.xml', 'brownv/tagfiles/br-e11.xml', 'brownv/tagfiles/br-a21.xml', 'brown1/tagfiles/br-j01.xml', 'brownv/tagfiles/br-a17.xml', 'brown1/tagfiles/br-l12.xml', 'brownv/tagfiles/br-e09.xml', 'brown2/tagfiles/br-g17.xml', 'brown2/tagfiles/br-g18.xml', 'brownv/tagfiles/br-g09.xml', 'brownv/tagfiles/br-l04.xml', 'brownv/tagfiles/br-l05.xml', 'brown2/tagfiles/br-l18.xml', 'brownv/tagfiles/br-d08.xml', 'brown1/tagfiles/br-k16.xml', 'brown2/tagfiles/br-f21.xml', 'brown2/tagfiles/br-n11.xml', 'brown1/tagfiles/br-j04.xml', 'brownv/tagfiles/br-e16.xml', 'brownv/tagfiles/br-a25.xml', 'brown2/tagfiles/br-n17.xml', 'brownv/tagfiles/br-g06.xml', 'brownv/tagfiles/br-e06.xml', 'brownv/tagfiles/br-a42.xml', 'brown1/tagfiles/br-g01.xml', 'brown1/tagfiles/br-j19.xml', 'brown2/tagfiles/br-n15.xml', 'brown1/tagfiles/br-j05.xml', 'brownv/tagfiles/br-b16.xml', 'brown1/tagfiles/br-n05.xml', 'brown1/tagfiles/br-a11.xml', 'brownv/tagfiles/br-d05.xml', 'brown2/tagfiles/br-e27.xml', 'brown2/tagfiles/br-l17.xml', 'brown2/tagfiles/br-g21.xml', 'brownv/tagfiles/br-b03.xml', 'brown1/tagfiles/br-r05.xml', 'brownv/tagfiles/br-g07.xml', 'brownv/tagfiles/br-e14.xml', 'brownv/tagfiles/br-f11.xml', 'brownv/tagfiles/br-g05.xml', 'brown2/tagfiles/br-g20.xml', 'brown1/tagfiles/br-k15.xml', 'brown1/tagfiles/br-k25.xml', 'brown2/tagfiles/br-g31.xml', 'brownv/tagfiles/br-f09.xml', 'brown1/tagfiles/br-p01.xml', 'brown2/tagfiles/br-n09.xml', 'brownv/tagfiles/br-d16.xml', 'brownv/tagfiles/br-a26.xml', 'brown2/tagfiles/br-p09.xml', 'brownv/tagfiles/br-p03.xml', 'brownv/tagfiles/br-b21.xml', 'brown2/tagfiles/br-j33.xml', 'brownv/tagfiles/br-f05.xml', 'brownv/tagfiles/br-b17.xml', 'brown2/tagfiles/br-j41.xml', 'brownv/tagfiles/br-e18.xml', 'brown1/tagfiles/br-k24.xml', 'brownv/tagfiles/br-j24.xml', 'brown2/tagfiles/br-e22.xml', 'brown1/tagfiles/br-j53.xml', 'brown2/tagfiles/br-f22.xml', 'brown1/tagfiles/br-k20.xml', 'brown2/tagfiles/br-g16.xml', 'brown1/tagfiles/br-j12.xml', 'brownv/tagfiles/br-a09.xml', 'brown1/tagfiles/br-k02.xml', 'brownv/tagfiles/br-a44.xml', 'brown1/tagfiles/br-b20.xml', 'brownv/tagfiles/br-b19.xml', 'brown1/tagfiles/br-k28.xml', 'brown1/tagfiles/br-k03.xml', 'brown1/tagfiles/br-j23.xml', 'brown2/tagfiles/br-n16.xml', 'brownv/tagfiles/br-a37.xml', 'brown2/tagfiles/br-h18.xml', 'brown2/tagfiles/br-l16.xml', 'brownv/tagfiles/br-l03.xml', 'brownv/tagfiles/br-b09.xml', 'brown1/tagfiles/br-j70.xml', 'brownv/tagfiles/br-a19.xml', 'brownv/tagfiles/br-a23.xml', 'brown2/tagfiles/br-j42.xml', 'brownv/tagfiles/br-b12.xml', 'brownv/tagfiles/br-c13.xml', 'brownv/tagfiles/br-a07.xml', 'brown2/tagfiles/br-f25.xml', 'brown2/tagfiles/br-l10.xml', 'brown1/tagfiles/br-k05.xml', 'brown1/tagfiles/br-a14.xml', 'brownv/tagfiles/br-e03.xml', 'brownv/tagfiles/br-c16.xml', 'brownv/tagfiles/br-a30.xml', 'brownv/tagfiles/br-r02.xml', 'brownv/tagfiles/br-e13.xml', 'brown2/tagfiles/br-j32.xml', 'brown1/tagfiles/br-r06.xml', 'brownv/tagfiles/br-b15.xml', 'brownv/tagfiles/br-j26.xml', 'brownv/tagfiles/br-e19.xml', 'brown1/tagfiles/br-k21.xml', 'brownv/tagfiles/br-b10.xml', 'brown2/tagfiles/br-f20.xml', 'brownv/tagfiles/br-a18.xml', 'brown2/tagfiles/br-f23.xml', 'brown2/tagfiles/br-g23.xml', 'brown1/tagfiles/br-j60.xml', 'brown1/tagfiles/br-k27.xml', 'brownv/tagfiles/br-g03.xml', 'brownv/tagfiles/br-h05.xml', 'brownv/tagfiles/br-n03.xml', 'brown2/tagfiles/br-e25.xml', 'brown1/tagfiles/br-k12.xml', 'brown2/tagfiles/br-h15.xml', 'brown2/tagfiles/br-h09.xml', 'brown2/tagfiles/br-h14.xml', 'brown1/tagfiles/br-e24.xml', 'brown1/tagfiles/br-r08.xml', 'brown1/tagfiles/br-j02.xml', 'brown1/tagfiles/br-j18.xml', 'brownv/tagfiles/br-c05.xml', 'brown2/tagfiles/br-h11.xml', 'brown2/tagfiles/br-g12.xml', 'brown2/tagfiles/br-n14.xml', 'brown1/tagfiles/br-j10.xml', 'brown1/tagfiles/br-e01.xml', 'brownv/tagfiles/br-a22.xml', 'brown2/tagfiles/br-f18.xml', 'brownv/tagfiles/br-a31.xml', 'brown2/tagfiles/br-g22.xml', 'brownv/tagfiles/br-a05.xml', 'brownv/tagfiles/br-a34.xml', 'brownv/tagfiles/br-b08.xml', 'brown2/tagfiles/br-e26.xml', 'brown1/tagfiles/br-d03.xml', 'brown1/tagfiles/br-k01.xml', 'brown1/tagfiles/br-r07.xml', 'brown1/tagfiles/br-j57.xml', 'brown1/tagfiles/br-k13.xml', 'brownv/tagfiles/br-a16.xml', 'brownv/tagfiles/br-p05.xml', 'brownv/tagfiles/br-c07.xml', 'brown2/tagfiles/br-g39.xml', 'brownv/tagfiles/br-a08.xml', 'brownv/tagfiles/br-d11.xml', 'brownv/tagfiles/br-a03.xml', 'brown1/tagfiles/br-a01.xml', 'brownv/tagfiles/br-m04.xml', 'brownv/tagfiles/br-a20.xml', 'brown1/tagfiles/br-g15.xml', 'brownv/tagfiles/br-c12.xml', 'brownv/tagfiles/br-l07.xml', 'brownv/tagfiles/br-a27.xml', 'brownv/tagfiles/br-e08.xml', 'brownv/tagfiles/br-c10.xml', 'brown1/tagfiles/br-g11.xml', 'brownv/tagfiles/br-f07.xml', 'brownv/tagfiles/br-b27.xml', 'brown1/tagfiles/br-e21.xml', 'brownv/tagfiles/br-c11.xml', 'brown1/tagfiles/br-j58.xml', 'brown1/tagfiles/br-j11.xml', 'brownv/tagfiles/br-n08.xml', 'brownv/tagfiles/br-a40.xml', 'brown1/tagfiles/br-m01.xml', 'brown1/tagfiles/br-j08.xml', 'brown1/tagfiles/br-j15.xml', 'brownv/tagfiles/br-b14.xml', 'brown2/tagfiles/br-r04.xml', 'brownv/tagfiles/br-j25.xml', 'brown2/tagfiles/br-j29.xml', 'brownv/tagfiles/br-n02.xml', 'brownv/tagfiles/br-b24.xml', 'brownv/tagfiles/br-b18.xml', 'brown1/tagfiles/br-j07.xml', 'brownv/tagfiles/br-d10.xml', 'brown1/tagfiles/br-c01.xml', 'brownv/tagfiles/br-g02.xml', 'brown2/tagfiles/br-l14.xml', 'brown1/tagfiles/br-k10.xml', 'brown1/tagfiles/br-f03.xml', 'brown2/tagfiles/br-p12.xml', 'brownv/tagfiles/br-d09.xml', 'brown2/tagfiles/br-l15.xml', 'brown1/tagfiles/br-j13.xml', 'brown2/tagfiles/br-h12.xml', 'brownv/tagfiles/br-a24.xml', 'brownv/tagfiles/br-f04.xml', 'brownv/tagfiles/br-b25.xml', 'brownv/tagfiles/br-b23.xml', 'brown2/tagfiles/br-f33.xml', 'brown1/tagfiles/br-m02.xml', 'brown1/tagfiles/br-h01.xml', 'brownv/tagfiles/br-p04.xml', 'brown2/tagfiles/br-l08.xml', 'brown1/tagfiles/br-j37.xml', 'brown1/tagfiles/br-k29.xml', 'brown2/tagfiles/br-j35.xml', 'brownv/tagfiles/br-b06.xml', 'brown1/tagfiles/br-k23.xml', 'brown1/tagfiles/br-j55.xml', 'brown2/tagfiles/br-f14.xml', 'brown2/tagfiles/br-h24.xml', 'brownv/tagfiles/br-e05.xml', 'brown1/tagfiles/br-b13.xml', 'brown2/tagfiles/br-g19.xml', 'brown2/tagfiles/br-h17.xml', 'brown1/tagfiles/br-k06.xml', 'brownv/tagfiles/br-e10.xml', 'brown2/tagfiles/br-l09.xml', 'brownv/tagfiles/br-d14.xml', 'brownv/tagfiles/br-b01.xml', 'brownv/tagfiles/br-g10.xml', 'brownv/tagfiles/br-d15.xml', 'brownv/tagfiles/br-a28.xml', 'brown2/tagfiles/br-n10.xml', 'brownv/tagfiles/br-e20.xml', 'brownv/tagfiles/br-a39.xml', 'brownv/tagfiles/br-m05.xml', 'brown1/tagfiles/br-c02.xml', 'brown2/tagfiles/br-j30.xml', 'brown1/tagfiles/br-k09.xml', 'brown2/tagfiles/br-g44.xml', 'brownv/tagfiles/br-c03.xml', 'brown1/tagfiles/br-k26.xml', 'brown2/tagfiles/br-g14.xml', 'brownv/tagfiles/br-d17.xml', 'brownv/tagfiles/br-c08.xml', 'brownv/tagfiles/br-e12.xml', 'brown2/tagfiles/br-f13.xml', 'brownv/tagfiles/br-g04.xml', 'brown1/tagfiles/br-j59.xml', 'brownv/tagfiles/br-a32.xml', 'brownv/tagfiles/br-n04.xml', 'brownv/tagfiles/br-p02.xml', 'brown1/tagfiles/br-k17.xml', 'brown1/tagfiles/br-f10.xml', 'brown1/tagfiles/br-j20.xml', 'brownv/tagfiles/br-c09.xml', 'brownv/tagfiles/br-h10.xml', 'brown2/tagfiles/br-f15.xml', 'brown1/tagfiles/br-r09.xml', 'brown1/tagfiles/br-j14.xml', 'brownv/tagfiles/br-m06.xml', 'brownv/tagfiles/br-c15.xml', 'brownv/tagfiles/br-d07.xml', 'brownv/tagfiles/br-a36.xml', 'brownv/tagfiles/br-f01.xml', 'brownv/tagfiles/br-j21.xml', 'brown1/tagfiles/br-k08.xml', 'brown2/tagfiles/br-p10.xml', 'brownv/tagfiles/br-h03.xml', 'brownv/tagfiles/br-a41.xml', 'brown1/tagfiles/br-k22.xml', 'brown1/tagfiles/br-j56.xml', 'brown2/tagfiles/br-e28.xml', 'brown1/tagfiles/br-k07.xml', 'brown2/tagfiles/br-h21.xml', 'brown1/tagfiles/br-l11.xml', 'brown1/tagfiles/br-d02.xml', 'brownv/tagfiles/br-b22.xml', 'brownv/tagfiles/br-l02.xml', 'brown2/tagfiles/br-f44.xml', 'brownv/tagfiles/br-h06.xml', 'brown1/tagfiles/br-k18.xml', 'brownv/tagfiles/br-h04.xml', 'brown1/tagfiles/br-k14.xml', 'brown1/tagfiles/br-j22.xml', 'brown1/tagfiles/br-d04.xml', 'brown2/tagfiles/br-n20.xml', 'brown2/tagfiles/br-n12.xml', 'brown1/tagfiles/br-k04.xml', 'brownv/tagfiles/br-b04.xml', 'brown1/tagfiles/br-j16.xml', 'brown2/tagfiles/br-f24.xml', 'brownv/tagfiles/br-e15.xml', 'brown1/tagfiles/br-a02.xml', 'brown1/tagfiles/br-j52.xml', 'brownv/tagfiles/br-b07.xml', 'brownv/tagfiles/br-n07.xml', 'brown1/tagfiles/br-f19.xml', 'brown2/tagfiles/br-g28.xml', 'brownv/tagfiles/br-p08.xml', 'brownv/tagfiles/br-m03.xml', 'brownv/tagfiles/br-b26.xml', 'brown2/tagfiles/br-e23.xml', 'brown2/tagfiles/br-g43.xml', 'brownv/tagfiles/br-n01.xml', 'brown1/tagfiles/br-e29.xml', 'brown2/tagfiles/br-j31.xml', 'brownv/tagfiles/br-g13.xml', 'brown2/tagfiles/br-f17.xml', 'brown2/tagfiles/br-j38.xml', 'brown2/tagfiles/br-f08.xml', 'brown1/tagfiles/br-a15.xml', 'brown1/tagfiles/br-c04.xml', 'brown1/tagfiles/br-k19.xml', 'brownv/tagfiles/br-p06.xml', 'brown2/tagfiles/br-p07.xml', 'brown2/tagfiles/br-l13.xml', 'brown1/tagfiles/br-d01.xml', 'brown2/tagfiles/br-f16.xml', 'brownv/tagfiles/br-f06.xml', 'brown1/tagfiles/br-j06.xml', 'brownv/tagfiles/br-l01.xml', 'brownv/tagfiles/br-c17.xml', 'brown1/tagfiles/br-a12.xml', 'brown1/tagfiles/br-a13.xml', 'brown1/tagfiles/br-j03.xml', 'brownv/tagfiles/br-a35.xml', 'brownv/tagfiles/br-c14.xml', 'brown2/tagfiles/br-e30.xml', 'brownv/tagfiles/br-h08.xml', 'brownv/tagfiles/br-d12.xml', 'brown1/tagfiles/br-e02.xml', 'brownv/tagfiles/br-f02.xml', 'brownv/tagfiles/br-a04.xml', 'brownv/tagfiles/br-e17.xml', 'brownv/tagfiles/br-f12.xml', 'brownv/tagfiles/br-a43.xml', 'brown2/tagfiles/br-p24.xml', 'brown2/tagfiles/br-h16.xml', 'brownv/tagfiles/br-e07.xml', 'brown1/tagfiles/br-j09.xml', 'brownv/tagfiles/br-a33.xml', 'brownv/tagfiles/br-r03.xml', 'brown1/tagfiles/br-f43.xml', 'brown1/tagfiles/br-k11.xml', 'brownv/tagfiles/br-b05.xml', 'brownv/tagfiles/br-a38.xml', 'brownv/tagfiles/br-a10.xml', 'brown2/tagfiles/br-h13.xml', 'brownv/tagfiles/br-g08.xml', 'brownv/tagfiles/br-b11.xml', 'brown1/tagfiles/br-j54.xml', 'brownv/tagfiles/br-d13.xml', 'brownv/tagfiles/br-b02.xml', 'brownv/tagfiles/br-a06.xml', 'brownv/tagfiles/br-j27.xml', 'brown1/tagfiles/br-e04.xml', 'brownv/tagfiles/br-d06.xml', 'brownv/tagfiles/br-j28.xml', 'brownv/tagfiles/br-n06.xml', 'brownv/tagfiles/br-h07.xml', 'brown1/tagfiles/br-j17.xml', 'brownv/tagfiles/br-h02.xml', 'brownv/tagfiles/br-r01.xml']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "random.seed(37)\n",
    "shuffled=list(allfiles)\n",
    "random.shuffle(shuffled)\n",
    "print(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#this cell will take 1-5 minutes to run - avoid rerunning it unnecessarily\n",
    "#training_sentences=extract_senses(shuffled[:300])\n",
    "#testing_sentences=extract_senses(shuffled[300:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4\n",
    "Use the functionality you have already developed to identify:\n",
    "* the ten most frequent monosemous words in the training data\n",
    "* the ten best candidates in the training data for evaluating binary classification algorithms for WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#find_monosemous(find_sense_distributions(training_sentences))\n",
    "\n",
    "#training_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Naive Bayes Classifiers for WSD\n",
    "We are going to train and use a NB classifier to identify the correct sense of a word.\n",
    "\n",
    "The functions below will get all of the sentences containing a given word and generate a bag-of-words representation suitable for a Naive Bayes classifier.\n",
    "\n",
    "Try it out on one of the words you identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def contains(sentence,astring):\n",
    "    '''\n",
    "    check whether sentence contains astring\n",
    "    '''\n",
    "    if len(sentence)>0:\n",
    "        tokens,tags=zip(*sentence)\n",
    "        #print(tokens,tags)\n",
    "        return astring in tokens\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_label(sentence,word):\n",
    "    '''\n",
    "    get the synset label for the word in this sentence\n",
    "    '''\n",
    "    count=0\n",
    "    label=\"none\"\n",
    "    for token,tag in sentence:\n",
    "        if token==word:\n",
    "            count+=1\n",
    "            label=str(tag)\n",
    "    if count !=1:\n",
    "        #print(\"Warning: {} occurs {} times in {}\".format(word,count,sentence))\n",
    "        pass\n",
    "    return label\n",
    "    \n",
    "def get_word_data(sentences,word):\n",
    "    '''\n",
    "    select sentences containing words and construct labelled data set where each sentence is represented using Bernouilli event model\n",
    "    '''\n",
    "    selected_sentences=[sentence for sentence in sentences if contains(sentence,word)]\n",
    "    word_data=[({token:True for (token,tag) in sentence},get_label(sentence,word)) for sentence in selected_sentences] \n",
    "    return word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train and test a NaiveBayesClassifier.  Here we are going to use the nltk one, but feel free to try out your own developed in earlier labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
    "\n",
    "#set myword to one of the words you identified as a good candidate for testing WSD algorithms in the earlier exercises\n",
    "myword=\"atom\"\n",
    "\n",
    "training=get_word_data(training_sentences,myword)\n",
    "testing=get_word_data(testing_sentences,myword)\n",
    "aclassifier=NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[({'appears': True,\n   'possible': True,\n   'set': True,\n   'abstraction': True,\n   'chlorine': True,\n   'atom': True,\n   'molecule': True,\n   'form': True,\n   'radical': True},\n  \"Synset('atom.n.01')\"),\n ({'furthermore': True,\n   'exchange': True,\n   'not': True,\n   'expected': True,\n   'be': True,\n   'sensitive': True,\n   'trace': True,\n   'amounts': True,\n   'impurities': True,\n   'abstraction': True,\n   'chlorine': True,\n   'atom': True,\n   'too': True,\n   'high': True,\n   'also': True,\n   'compete': True,\n   'very': True,\n   'effectively': True,\n   'scavenger': True,\n   'radicals': True},\n  \"Synset('atom.n.01')\")]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "Write a function to evaluate the accuracy of your classifier on some test data.\n",
    "\n",
    "Test it using `testing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[({'o': True,\n   'atoms': True,\n   'sheet': True,\n   'are': True,\n   'cr': True,\n   'atom': True,\n   'surrounded': True,\n   'octahedron': True},\n  \"Synset('atom.n.01')\"),\n ({'found': True,\n   'be': True,\n   'paramagnetic': True,\n   'three': True,\n   'unpaired': True,\n   'electron': True,\n   'chromium': True,\n   'atom': True,\n   'molecular': True,\n   'susceptibility': True},\n  \"Synset('atom.n.01')\")]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy of NB classification on testing data is 1.0 , 2 out of 2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def evaluate(cls,test_data):\n",
    "    correct=0\n",
    "    wrong=0\n",
    "    predictions={}\n",
    "    actual={}\n",
    "    for doc,label in test_data:\n",
    "        prediction=cls.classify(doc)\n",
    "        predictions[prediction]=predictions.get(prediction,0)+1\n",
    "        actual[label]=actual.get(label,0)+1\n",
    "        if prediction==label:\n",
    "            correct+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    acc=correct/(correct+wrong)\n",
    "    print(\"Accuracy of NB classification on testing data is {} , {} out of {}\".format(acc,correct,correct+wrong))\n",
    "    \n",
    "evaluate(aclassifier,testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "Write a function which will return the precision of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3\n",
    "Write a function `train_and_test()` which gets the appropriate training and testing data for a given word, builds a classifier and outputs the precision with which each class is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Sussex NLTK root directory is \\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-8f38849b541a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mevaluate_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-8f38849b541a>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#evaluate(classifier,testing)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mevaluate_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_precision' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'evaluate_precision' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from classifiercode import *\n",
    "def train_and_test(word):\n",
    "    training=get_word_data(training_sentences,word)\n",
    "    testing=get_word_data(testing_sentences,word)\n",
    "    classifier=NaiveBayesClassifier.train(training)\n",
    "    #evaluate(classifier,testing)\n",
    "    evaluate_precision(classifier,testing)\n",
    "\n",
    "train_and_test(\"best\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4\n",
    "* Run `train_and_test()` on each of your candidate words identified earlier in the exercise.  \n",
    "* Display results in a pandas dataframe\n",
    "* Calculate average precision for each word\n",
    "* Calculate the average average precision score for the set of candidate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}